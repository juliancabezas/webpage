---
title: Trabajar con un base de datos en .csv o .txt más grande que tu memoria RAM en R utilizando SQLite
author: Julián Cabezas
date: '2019-03-20'
slug: tutorial-2
categories:
  - R
  - Tutoriales
tags:
  - R
  - Tutoriales
  - SQL
  - SQLite
  - bigdata
  - RAM
  - memory
  - memoria
  - csv
  - txt
image:
  caption: ''
  focal_point: ''
summary: '¿Cansado del mensaje "out of memory" cuando intentas abrir una base de datos en R?, '
header:
  image: ""
  caption: "La idea es alcanzar a lograr este nivel de equilibrio espiritual"
output:
  blogdown::html_page:
    toc: true
    number_sections: false
    toc_depth: 2
---

No se si es el caso de todos, pero por mi parte, cada vez que llego a un nuevo trabajo, me pasan **el peor computador de la oficina**, usualmente 4 Gb de RAM a lo sumo (y con Windows de 32 bits si tienes muy mala suerte, como me pasó a mi). Como ocupo R para todo, se me hace muy dificil trabajar con bases de datos grandes, a veces mayores a la memoría asignada a R. Este tutorial sirve tambien si tenemos una base de datos MUY grande

En este tutorial vamos a revisar cuanta memoria RAM tiene asignada R en el sistema, y a crear una base de datos SQLite de la cual vamos a poder ir extrayendo datos y realizando analisis que pueden ser manejados en nuestra memoria RAM, todo con la ayuda de una función que adapte de este [gist de vnijs](https://gist.github.com/vnijs/e53a68c957747e82c2e3)


## Primero lo primero: ¿Cuanta memoria tengo?

## CSV o TXT a SQLlite

### Crear la base de datos

### La proemtida funcion

### Mover la csv o txt a la base de datos SQLlite

## Analizar y recoger datos con dplyr





**Espero sus comentarios y dudas!**

